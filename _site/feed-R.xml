<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
	<channel>
		<title>Joel Carlson - R ramblings</title>
		<description>Posts categorized as 'R'</description>
		<link>http://joelcarlson.github.io</link>
		<atom:link href="http://joelcarlson.github.io/feed-R.xml" rel="self" type="application/rss+xml" />
		
			<item>
				<title>The Dangers(?) of Improperly Centering and Scaling Your Data</title>
					<description>&lt;p&gt;Recently I was at a conference where many of the presentations involved some sort of machine learning. One thing that I noticed was that often times the speakers would make no mention of being careful to not contaminate their test set with information from their training set.&lt;/p&gt;

&lt;p&gt;For example, for certain machine learning algorithms, such as support vector machines, centering and scaling your data is essential for the algorithm to perform. Centering and scaling the data is a process by which you transform each feature such that its mean becomes 0, and variance becomes 1. If you center and scale your data before splitting it into training and test sets, then you have used information from your training set to make calculations on your test set. This is a problem. Or could be, at least.&lt;/p&gt;

&lt;p&gt;This was concerning me at the conference, but I didn&amp;#39;t speak up about it because although I had been instructed to avoid this mistake, and it made intuitive sense to me, I had never actually tested to see if there was a significant difference between the two methods. &lt;/p&gt;

&lt;p&gt;In this post, I am going to explore this by assessing the accuracy of support vector machine models on three datasets: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Not centered or scaled&lt;/li&gt;
&lt;li&gt;Training and testing centered and scaled together&lt;/li&gt;
&lt;li&gt;Training and testing centered separately&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Datawise, we will use a set from the &lt;a href=&quot;http://archive.ics.uci.edu/ml/datasets/Wine&quot;&gt;UCI machine learning repository&lt;/a&gt;. The dataset is a series of wine measurements, quantifying things like &amp;quot;Alcohol Content&amp;quot;, &amp;quot;Color Intensity&amp;quot;, and &amp;quot;Hue&amp;quot; for 178 wines. The goal is to predict the region the wine came from based on the measurements. &lt;/p&gt;

&lt;h2&gt;Summarizing the data&lt;/h2&gt;

&lt;p&gt;Let&amp;#39;s take a quick look at the mean and standard deviation of each column in the data (sorted by SD):&lt;/p&gt;

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style=&quot;text-align:left;&quot;&gt; Variable &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; Mean &lt;/th&gt;
   &lt;th style=&quot;text-align:right;&quot;&gt; SD &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Proline &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 746.89 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 314.91 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Magnesium &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 99.74 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 14.28 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Alcalinity &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 19.49 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 3.34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; ColorIntensity &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 5.06 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.32 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Acid &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.34 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1.12 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Flavanoids &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.03 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Alcohol &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 13.00 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; OpticalDensity &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.61 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.71 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Phenols &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.30 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Proanthocyanins &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 1.59 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.57 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Ash &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 2.37 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.27 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; Hue &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.96 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.23 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style=&quot;text-align:left;&quot;&gt; NonFlavanoidPhenols &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.36 &lt;/td&gt;
   &lt;td style=&quot;text-align:right;&quot;&gt; 0.12 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;There are 13 variables in the data, but we are going to use only the 5 with the highest standard deviation, since this is for demonstration purposes, not pure predictive accuracy. Although Alcohol is not in the top 5, we are going to use it as well (because hey, we&amp;#39;re talking about wine!)&lt;/p&gt;

&lt;h2&gt;A bit of intuition&lt;/h2&gt;

&lt;p&gt;Just so that we have a feel for the data, let&amp;#39;s plot a variable or two:
We might be able to guess that there is some relationship between alcohol content and region:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot1.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;And indeed there is, not a big surprise there.&lt;/p&gt;

&lt;p&gt;Wikipedia tells me that, during brewing, &lt;a href=&quot;https://en.wikipedia.org/wiki/Proline&quot;&gt;Proline&lt;/a&gt; may produce haze, so perhaps it would be related to Color Intensity?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot2.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;As expected. It looks like these variables are going to be able to feed a pretty accurate model. Based on the way the second plot is organized into clusters I imagine even a simple approach like KNN would do well.&lt;/p&gt;

&lt;h2&gt;Building the models&lt;/h2&gt;

&lt;p&gt;The features of this data vary wildly in scale, for example, the range of the &lt;code&gt;Proline&lt;/code&gt; column is from 278 to 1680, whereas the &lt;code&gt;Acid&lt;/code&gt; column goes from 0.74 to 5.80. This is an issue for support vector machines (and some other algorithms), so we need to center and scale the data.&lt;/p&gt;

&lt;p&gt;For each situation described above, I trained 1000 svm models from the &lt;code&gt;e1071&lt;/code&gt; R package (with default parameters) and recorded the accuracy. Each model was trained on a random subset of 50% of the data, and tested on the remaining 50%. The test set acccuracy distributions in each situation are presented as histograms.&lt;/p&gt;

&lt;h3&gt;No centering and scaling&lt;/h3&gt;

&lt;p&gt;To demonstrate the importance of centering and scaling for support vector machines, the accuracy was first assessed without centering and scaling:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot3.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;As we can see, the accuracy is pretty abysmal. There are three categories, so the mean of 0.415 is better than guessing, but not by much. Of course, this was expected, centering and scaling are a necessary step for svms.&lt;/p&gt;

&lt;h3&gt;Scaling Training and Test together&lt;/h3&gt;

&lt;p&gt;This time we scale the training and test together, and then split them apart for training of the model. This means that there is some information from the test set leaking into the training set, and vice versa.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot4.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;Clearly that made the difference, accuracy is nearly perfect. &lt;/p&gt;

&lt;h3&gt;Scaling separately (the right way)&lt;/h3&gt;

&lt;p&gt;Well, this is the right way. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot5.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;So, it appears that there is just the teeensiest increase in accuracy if we do it the right way. Is it statistically significant, though?&lt;/p&gt;

&lt;h3&gt;Statistical Significance&lt;/h3&gt;

&lt;p&gt;We can assess whether or not there is a difference in the mean accuracy between scaling together and scaling separately by using a t-test. From the histograms we can see that the accuracy scores are very roughly normal, so t-tests are appropriate here.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt; 
    Welch Two Sample t-test
 
 data: Separate and Together
 t = 3.8542, df = 1996.389, p-value = 0.0001198
 alternative hypothesis: true difference in means is not equal to 0
 95 percent confidence interval:
      0.00179 0.00552
 sample estimates:
 mean of x mean of y 
      0.939 0.936&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/figs/CentreScale/plot6.png&quot; width=60%/&gt;&lt;/p&gt;

&lt;p&gt;The difference is extremely small (around 0.4%), but it exists and is statistically significant.  &lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;As we saw, centering and scaling the data the proper way actually, for this dataset, leads to a tiny but statistically significant &lt;strong&gt;increase&lt;/strong&gt; in the mean accuracy of the svm models. 
I have to admit to being surpised, I expected the opposite result! It would be interesting to see how the size of the dataset, and number of variables in the model impact this difference.&lt;/p&gt;

&lt;p&gt;Of course, this was no fully rigorous test, but I do think it adds to the evidence that you should always center and scale your training and test data separately (not least because it&amp;#39;s the correct way!).&lt;/p&gt;

&lt;p&gt;This post has a small discussion on reddit &lt;a href=&quot;https://www.reddit.com/r/statistics/comments/3heml4/the_dangers_of_improperly_centering_and_scaling/&quot;&gt;here&lt;/a&gt; and a reproducible version with code can be found &lt;a href=&quot;https://github.com/joelcarlson/joelcarlson.github.io/blob/master/reproducibleDocs/CentreScale.Rmd&quot;&gt;here&lt;/a&gt;&lt;/p&gt;
</description>
				<pubDate>Tue, 18 Aug 2015 00:00:00 +0900</pubDate>
				<link>http://joelcarlson.github.io/r/2015/08/18/CentreScale/</link>
				<guid isPermaLink="true">http://joelcarlson.github.io/r/2015/08/18/CentreScale/</guid>
			</item>
		
			<item>
				<title>Introducing radiomics for R</title>
					<description>&lt;p&gt;The &lt;code&gt;radiomics&lt;/code&gt; package is a set of tools for computing texture matrices from images, and features derived from the matrices. &lt;/p&gt;

&lt;p&gt;You can install the package either from CRAN, or the development version from github (recommended) using:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;install.packages&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;radiomics&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

devtools&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;install_github&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;joelcarlson/radiomics&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; ref&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;develop&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h1&gt;Texture Matrices&lt;/h1&gt;

&lt;p&gt;In the package are functions for calculating several different types of matrices used to quantify the texture of an image in the form of a matrix.&lt;/p&gt;

&lt;h2&gt;Gray Level Co-occurrence Matrix&lt;/h2&gt;

&lt;p&gt;The first texture matrix is the gray level co-occurence matrix (GLCM). GLCMs take an image (as a matrix), an angle (&amp;quot;0&amp;quot;, &amp;quot;45&amp;quot;, &amp;quot;90&amp;quot;, or &amp;quot;135&amp;quot;), and an integer distance, d. The axes of the GLCM are defined by the grey levels present in the image. Each pixel of the image is scanned and stored as a &amp;quot;reference pixel&amp;quot;. The reference pixel is then compared to the pixel that is distance d at angle theta (where &amp;quot;0&amp;quot; degrees is the pixel to the right, &amp;quot;90&amp;quot; is the pixel above) away from the reference pixel, known as the neighbor pixel. Each time a reference value and neighbor value pair is found, the corresponding row and column of the GLCM is incremented by 1. &lt;/p&gt;

&lt;p&gt;A visual example shows this process. Pixels in the image are colored and labelled by grey value. The GLCM is set up such that each pixel value is represented on each axis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/m9MKq1I.png&quot; height=&quot;227px&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We count the number of times each pair of grey levels occurs, for example, if angle = &amp;quot;0&amp;quot; and d = 1, for the grey level of 1, there is one 1:1 pair:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/z5xFw6C.png&quot; height=&quot;227px&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;While there are two 1:3 pairs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/4L8dSgf.png&quot; height=&quot;227px&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Continuing in this fashion for each grey level, we end up with a GLCM filled with counts.&lt;/p&gt;

&lt;p&gt;By convention, we sum the GLCM and the GLCMs transpose to obtain a symmetric matrix:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/GdVzVxN.png&quot; height=&quot;227px&quot; width=&quot;829px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can be accomplished using the &lt;code&gt;radiomics&lt;/code&gt; package as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;radiomics&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
image &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; nrow&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
glcm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;image&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; normalize&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   1 2 3 4
## 1 2 2 3 0
## 2 2 0 2 1
## 3 3 2 0 2
## 4 0 1 2 2&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Normally, GLCMs are normalized before features are calculated, this is the default situation for the &lt;code&gt;glcm()&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;More information about the GLCM can be found &lt;a href=&quot;http://www.fp.ucalgary.ca/mhallbey/tutorial.htm&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;Gray Level Run Length Matrix&lt;/h2&gt;

&lt;p&gt;The GLRLM is a matrix which attempts to quantify runs of the same grey level in the image. The GLRLM is set up slightly differently than the GLCM; instead of having grey levels along the abscissa of the table the GLRLM has run lengths.&lt;/p&gt;

&lt;p&gt;As with the GLCM, an angle is required (one of &amp;quot;0&amp;quot;, &amp;quot;45&amp;quot;, &amp;quot;90&amp;quot;, or &amp;quot;135&amp;quot;). Below is an example using &amp;quot;0&amp;quot;, note that the image matrix is not the same as the GLCM example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/aTapTC1.png&quot; height=&quot;227px&quot; width=&quot;478x&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For each run of a given length we count how many times that length occurs for each grey level. Here, a run length of 1 pixel occurs 3 times for the yellow pixels, and a run length of 3 occurs once for the blue pixels.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/u87fW55.png&quot; height=&quot;227px&quot; width=&quot;545px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We complete this for all pixels in the image to obtain the final GLRLM:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/b61vqV2.png&quot; height=&quot;227px&quot; width=&quot;545px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This can be accomplished using the radiomics package with the command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;image &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; nrow&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
glrlm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;image&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   1 2 3 4
## 1 0 1 0 0
## 2 3 1 0 0
## 3 2 1 0 0
## 4 0 1 1 0&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Note the extra run length column, the number of run length columns is a function of the dimensions of the image. If the run length is possible (in this case, if there were 4 pixels in a row), there will be a column for it in the output. This output can be truncated by specifying the maximum run length you wish to search for:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;glrlm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;image&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; max_run_length&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   1 2 3
## 1 0 1 0
## 2 3 1 0
## 3 2 1 0
## 4 0 1 1&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2&gt;Gray Level Size Zone Matrix&lt;/h2&gt;

&lt;p&gt;The goal of the GLSZM is to quantify regions of contiguous pixels in the image. The GLSZM is set up in the same way as the GLRLM, except along the abscissa are size zones rather than run lengths. A size zone is defined as a collection of 9-connected pixels (ie. connected on their edges and corners) of the same grey level.&lt;/p&gt;

&lt;p&gt;For the GLSZM we will use the same image as for the GLCM. Rather than labeling grey levels, contiguous size zones are labeled with their size:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/vNQTAsz.png&quot; height=&quot;227px&quot; width=&quot;496px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For each color we count the number of zones of a given size, here for example, among other size zones, there are two red zones of size 1, a single blue zone of size 2, and a single light blue zone of size 3:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://i.imgur.com/UezvMmX.png&quot; height=&quot;227px&quot; width=&quot;496px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;GLSZMs can be calculated using the &lt;code&gt;glszm&lt;/code&gt; function:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;image &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; nrow&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
glszm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;image&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   1 2 3
## 1 2 0 1
## 2 0 0 1
## 3 1 0 1
## 4 2 1 0&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;For more information on the GLSZM see &lt;a href=&quot;http://thibault.biz/Research/ThibaultMatrices/GLSZM/GLSZM.html&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;Calculating Features&lt;/h1&gt;

&lt;p&gt;From the texture matrices it is possible to calculate many different features. These are summarized in the following table:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th align=&quot;left&quot;&gt;First Order&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;GLCM&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;GLRLM&lt;/th&gt;
&lt;th align=&quot;left&quot;&gt;GLSZM&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;energy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;mean&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;GLN&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;SAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;entropy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;variance&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;HGLRE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;kurtosis&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;autoCorrelation&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LRE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;IV&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;meanDeviation&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;cProminence&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LRHGLE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;SZV&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;skewness&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;cShade&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LRLGLE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;ZP&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;uniformity&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;cTendency&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LGLRE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LIE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;mean&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;contrast&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;RLN&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;HIE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;median&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;correlation&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;RP&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LISAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;max&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;differenceEntropy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;SRE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;HISAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;min&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;dissimilarity&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;SRHGLE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;LILAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;diff&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;energy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;SRLGLE&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;HILAE&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;var&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;entropy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;RMS&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;homogeneity1&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;sd&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;homogeneity2&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;IDMN&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;IDN&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;inverseVariance&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;maxProb&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;sumAverage&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;sumEntropy&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;sumVariance&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;td align=&quot;left&quot;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Further information and mathematical definitions of these quantities can be found &lt;a href=&quot;http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0102107#s5&quot;&gt;here.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;In the &lt;code&gt;radiomics&lt;/code&gt; package, each feature associated with a given matrix can be calculated using the &lt;code&gt;calc_features()&lt;/code&gt; function. For example:&lt;/p&gt;

&lt;p&gt;First order features are calculated on the image, and are prefixed with &amp;#39;calc&amp;#39;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;calc_features&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;hallbey&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;GLCM features are calculated if &lt;code&gt;calc_features()&lt;/code&gt; is passed a GLCM:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;hbGLCM &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; glcm&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;hallbey&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
calc_features&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;hbGLCM&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;And so on for the other texture matrix types.&lt;/p&gt;
</description>
				<pubDate>Fri, 10 Jul 2015 00:00:00 +0900</pubDate>
				<link>http://joelcarlson.github.io/r/2015/07/10/radiomics-package/</link>
				<guid isPermaLink="true">http://joelcarlson.github.io/r/2015/07/10/radiomics-package/</guid>
			</item>
		
	</channel>
</rss>
